{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f782bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from torch.utils.data import TensorDataset\n",
    "from settings import FEATURES, BASE_DIR\n",
    "from data import load_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c776e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   genres           200 non-null    object \n",
      " 1   rating           200 non-null    float64\n",
      " 2   no_of_votes      200 non-null    int64  \n",
      " 3   meta_score       200 non-null    float64\n",
      " 4   release_date     200 non-null    float64\n",
      " 5   gross            200 non-null    float64\n",
      " 6   budget           200 non-null    float64\n",
      " 7   countries        200 non-null    object \n",
      " 8   log_budget       200 non-null    float64\n",
      " 9   log_no_of_votes  200 non-null    float64\n",
      " 10  log_gross        200 non-null    float64\n",
      " 11  log_gross_bin    200 non-null    int64  \n",
      "dtypes: float64(8), int64(2), object(2)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_path = os.path.join(BASE_DIR, \"dataset\", \"test.csv\")\n",
    "test_df = pd.read_csv(test_path)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d8023d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import _split_column\n",
    "from data import _apply_target_encoding\n",
    "import joblib\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def process_test_data(df_test: pd.DataFrame, features, encoding_dir: str):\n",
    "    import json\n",
    "\n",
    "    # T√°ch genres v√† countries\n",
    "    df_test['genres_list'] = _split_column(df_test, 'genres')\n",
    "    df_test['countries_list'] = _split_column(df_test, 'countries')\n",
    "\n",
    "    # Load encoding t·ª´ file json\n",
    "    with open(os.path.join(encoding_dir, \"genre_encoded.json\"), encoding='utf-8') as f:\n",
    "        genre_encoding = json.load(f)\n",
    "\n",
    "    with open(os.path.join(encoding_dir, \"country_encoded.json\"), encoding='utf-8') as f:\n",
    "        country_encoding = json.load(f)\n",
    "\n",
    "    # √Åp d·ª•ng encoding ƒë·ªÉ t·∫°o ƒë·∫∑c tr∆∞ng th·ªëng k√™\n",
    "    _apply_target_encoding(df_test, df_test['genres_list'], genre_encoding, 'genre_stat_feature')\n",
    "    _apply_target_encoding(df_test, df_test['countries_list'], country_encoding, 'country_stat_feature')\n",
    "\n",
    "    # Log transform c√°c ƒë·∫∑c tr∆∞ng\n",
    "    for col in ['country_stat_feature', 'genre_stat_feature']:\n",
    "        df_test[f'log_{col}'] = np.log1p(df_test[f\"{col}\"])\n",
    "\n",
    "    # Log transform c√°c c·ªôt s·ªë kh√°c trong FEATURES\n",
    "    df_test['log_no_of_votes'] = np.log1p(df_test['no_of_votes'])\n",
    "    df_test['log_budget'] = np.log1p(df_test['budget'])\n",
    "\n",
    "    # L∆∞u l·∫°i c·ªôt 'gross' tr∆∞·ªõc khi ch·ªâ l·∫•y c√°c c·ªôt trong FEATURES\n",
    "    y_test = df_test['gross'].values\n",
    "\n",
    "    # Ch·ªâ l·∫•y c√°c c·ªôt c·∫ßn thi·∫øt trong FEATURES\n",
    "    df_test = df_test[features]\n",
    "\n",
    "    # Ki·ªÉm tra xem c√≥ ƒë·ªß c√°c c·ªôt trong FEATURES kh√¥ng\n",
    "    missing_cols = [col for col in features if col not in df_test.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "\n",
    "    # Load scaler\n",
    "    scaler_path = os.path.join(encoding_dir, \"scaler.pkl\")\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # Chu·∫©n h√≥a d·ªØ li·ªáu test\n",
    "    X_test = scaler.transform(df_test.values)\n",
    "\n",
    "    return X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf5245d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing with model from Fold 1\n",
      "üìä Fold 1 - R2: 0.5889 | MAE: 62763633.3991 | MAPE: 44.9413\n",
      "\n",
      "üîç Testing with model from Fold 2\n",
      "üìä Fold 2 - R2: 0.5705 | MAE: 65795168.8043 | MAPE: 40.3588\n",
      "\n",
      "üîç Testing with model from Fold 3\n",
      "üìä Fold 3 - R2: 0.5775 | MAE: 64040804.1345 | MAPE: 20.8085\n",
      "\n",
      "üîç Testing with model from Fold 4\n",
      "üìä Fold 4 - R2: 0.5737 | MAE: 62959194.6230 | MAPE: 32.8189\n",
      "\n",
      "üîç Testing with model from Fold 5\n",
      "üìä Fold 5 - R2: 0.5668 | MAE: 66462841.9493 | MAPE: 59.3389\n"
     ]
    }
   ],
   "source": [
    "fold_scores = []\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nüîç Testing with model from Fold {fold}\")\n",
    "\n",
    "    fold_dir = f\"best_models/GB_model/fold_{fold}\"\n",
    "    model_path = os.path.join(fold_dir, \"model.pkl\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ö†Ô∏è Missing model for fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    # Load model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # X·ª≠ l√Ω d·ªØ li·ªáu test\n",
    "    fold_path = f\"best_models/GB_model\"\n",
    "    X_test, y_test = load_data_test(test_df, features=FEATURES, folder_path=fold_path, fold=fold, target=\"gross\")\n",
    "\n",
    "    # D·ª± ƒëo√°n v√† ƒë√°nh gi√°\n",
    "    log_pred = model.predict(X_test)\n",
    "    y_pred = np.expm1(log_pred)  # Chuy·ªÉn ƒë·ªïi v·ªÅ gi√° tr·ªã g·ªëc\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"üìä Fold {fold} - R2: {r2:.4f} | MAE: {mae:.4f} | MAPE: {mape:.4f}\")\n",
    "    fold_scores.append((fold, r2, mae, mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b2ce1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà AVERAGE over folds - R2: 0.5755 | MAE: 64404328.5820 | MAPE: 39.6533\n"
     ]
    }
   ],
   "source": [
    "# Trung b√¨nh k·∫øt qu·∫£ c√°c fold\n",
    "r2_avg = np.mean([s[1] for s in fold_scores])\n",
    "mae_avg = np.mean([s[2] for s in fold_scores])\n",
    "mape_avg = np.mean([s[3] for s in fold_scores])\n",
    "\n",
    "print(f\"\\nüìà AVERAGE over folds - R2: {r2_avg:.4f} | MAE: {mae_avg:.4f} | MAPE: {mape_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f39ea3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Loading model and encoding from Fold 1\n",
      "\n",
      "üîç Loading model and encoding from Fold 2\n",
      "\n",
      "üîç Loading model and encoding from Fold 3\n",
      "\n",
      "üîç Loading model and encoding from Fold 4\n",
      "\n",
      "üîç Loading model and encoding from Fold 5\n",
      "\n",
      "üìä Ensemble Results (Average of 5 folds):\n",
      "üîπ R2: 0.5878 | MAE: 63106128.2808 | MAPE: 39.6263\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "y_test = None  # Ch·ªâ c·∫ßn l·∫•y y_test m·ªôt l·∫ßn\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nüîç Loading model and encoding from Fold {fold}\")\n",
    "\n",
    "    fold_dir = f\"best_models/GB_model/fold_{fold}\"\n",
    "    model_path = os.path.join(fold_dir, \"model.pkl\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ö†Ô∏è Missing model for fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # X·ª≠ l√Ω d·ªØ li·ªáu test (s·ª≠ d·ª•ng encoding + scaler c·ªßa t·ª´ng fold)\n",
    "    fold_path = f\"best_models/GB_model\"\n",
    "    X_test_fold, y_test_fold = load_data_test(test_df, features=FEATURES, folder_path=fold_path, fold=fold, target=\"gross\")\n",
    "\n",
    "    # Ch·ªâ c·∫ßn l∆∞u y_test m·ªôt l·∫ßn (gi·ªëng nhau cho m·ªçi fold)\n",
    "    if y_test is None:\n",
    "        y_test = y_test_fold\n",
    "\n",
    "    # D·ª± ƒëo√°n v√† l∆∞u l·∫°i\n",
    "    log_pred = model.predict(X_test_fold)  # S·ª≠ d·ª•ng X_test_fold thay v√¨ X_test\n",
    "    y_pred_fold = np.expm1(log_pred)  # Chuy·ªÉn ƒë·ªïi v·ªÅ gi√° tr·ªã g·ªëc\n",
    "\n",
    "    all_preds.append(y_pred_fold)\n",
    "\n",
    "# Trung b√¨nh d·ª± ƒëo√°n t·ª´ t·∫•t c·∫£ m√¥ h√¨nh\n",
    "y_pred_avg = np.mean(all_preds, axis=0)\n",
    "\n",
    "# ƒê√°nh gi√°\n",
    "r2 = r2_score(y_test, y_pred_avg)\n",
    "mae = mean_absolute_error(y_test, y_pred_avg)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_avg)\n",
    "\n",
    "print(f\"\\nüìä Ensemble Results (Average of 5 folds):\")\n",
    "print(f\"üîπ R2: {r2:.4f} | MAE: {mae:.4f} | MAPE: {mape:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
